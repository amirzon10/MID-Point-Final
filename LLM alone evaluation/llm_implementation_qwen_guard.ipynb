{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bade103a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/Flashragtest/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from flashrag.config import Config\n",
    "import os\n",
    "from flashrag.utils import get_dataset\n",
    "from flashrag.pipeline import SequentialPipeline\n",
    "from flashrag.prompt import PromptTemplate\n",
    "\n",
    "parent = os.path.abspath(os.path.join(os.getcwd(), \"..\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec95574",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_dict = { \n",
    "    'data_dir': f'{parent}/dataset',\n",
    "    'dataset_dir': f'{parent}/dataset',\n",
    "    'dataset_path': f'{parent}/dataset',\n",
    "    'split': 'test',\n",
    "    'index_path': f'{parent}/dataset/corpus/e5_Flat.index',\n",
    "    'corpus_path': f'{parent}/dataset/corpus/general_knowledge.jsonl',\n",
    "    'model2path': {'e5': f'{parent}/models/e5-base-v2', 'Qwen3Guard-Gen-0.6B': f'{parent}/models/Qwen3Guard-Gen-0.6B'},\n",
    "    'generator_model': 'Qwen3Guard-Gen-0.6B',\n",
    "    'metrics': ['em', 'f1', 'acc'],\n",
    "    'retrieval_topk': 0\n",
    "}\n",
    "\n",
    "config = Config(config_dict=config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9436427f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"yaml_loader\": \"<class 'yaml.loader.FullLoader'>\",\n",
      "  \"file_config\": {},\n",
      "  \"variable_config\": {\n",
      "    \"data_dir\": \"/Volumes/KINGSTON/mid-point/dataset\",\n",
      "    \"dataset_dir\": \"/Volumes/KINGSTON/mid-point/dataset\",\n",
      "    \"dataset_path\": \"/Volumes/KINGSTON/mid-point/dataset\",\n",
      "    \"split\": \"test\",\n",
      "    \"index_path\": \"/Volumes/KINGSTON/mid-point/dataset/corpus/e5_Flat.index\",\n",
      "    \"corpus_path\": \"/Volumes/KINGSTON/mid-point/dataset/corpus/general_knowledge.jsonl\",\n",
      "    \"model2path\": {\n",
      "      \"e5\": \"/Volumes/KINGSTON/mid-point/models/e5-base-v2\",\n",
      "      \"Qwen3Guard-Gen-0.6B\": \"/Volumes/KINGSTON/mid-point/models/Qwen3Guard-Gen-0.6B\"\n",
      "    },\n",
      "    \"generator_model\": \"Qwen3Guard-Gen-0.6B\",\n",
      "    \"metrics\": [\n",
      "      \"em\",\n",
      "      \"f1\",\n",
      "      \"acc\"\n",
      "    ],\n",
      "    \"retrieval_topk\": 0\n",
      "  },\n",
      "  \"external_config\": {\n",
      "    \"data_dir\": \"/Volumes/KINGSTON/mid-point/dataset\",\n",
      "    \"dataset_dir\": \"/Volumes/KINGSTON/mid-point/dataset\",\n",
      "    \"dataset_path\": \"/Volumes/KINGSTON/mid-point/dataset\",\n",
      "    \"split\": \"test\",\n",
      "    \"index_path\": \"/Volumes/KINGSTON/mid-point/dataset/corpus/e5_Flat.index\",\n",
      "    \"corpus_path\": \"/Volumes/KINGSTON/mid-point/dataset/corpus/general_knowledge.jsonl\",\n",
      "    \"model2path\": {\n",
      "      \"e5\": \"/Volumes/KINGSTON/mid-point/models/e5-base-v2\",\n",
      "      \"bge\": \"BAAI/bge-base-en-v1.5\",\n",
      "      \"contriever\": \"facebook/contriever\",\n",
      "      \"llama2-7B-chat\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
      "      \"llama2-7B\": \"meta-llama/Llama-2-7b-hf\",\n",
      "      \"llama2-13B\": \"meta-llama/Llama-2-13b-hf\",\n",
      "      \"llama2-13B-chat\": \"meta-llama/Llama-2-13b-chat-hf\",\n",
      "      \"Qwen3Guard-Gen-0.6B\": \"/Volumes/KINGSTON/mid-point/models/Qwen3Guard-Gen-0.6B\"\n",
      "    },\n",
      "    \"generator_model\": \"Qwen3Guard-Gen-0.6B\",\n",
      "    \"metrics\": [\n",
      "      \"em\",\n",
      "      \"f1\",\n",
      "      \"acc\"\n",
      "    ],\n",
      "    \"retrieval_topk\": 0\n",
      "  },\n",
      "  \"internal_config\": {\n",
      "    \"model2path\": {\n",
      "      \"e5\": \"/Volumes/KINGSTON/mid-point/models/e5-base-v2\",\n",
      "      \"bge\": \"BAAI/bge-base-en-v1.5\",\n",
      "      \"contriever\": \"facebook/contriever\",\n",
      "      \"llama2-7B-chat\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
      "      \"llama2-7B\": \"meta-llama/Llama-2-7b-hf\",\n",
      "      \"llama2-13B\": \"meta-llama/Llama-2-13b-hf\",\n",
      "      \"llama2-13B-chat\": \"meta-llama/Llama-2-13b-chat-hf\",\n",
      "      \"Qwen3Guard-Gen-0.6B\": \"/Volumes/KINGSTON/mid-point/models/Qwen3Guard-Gen-0.6B\"\n",
      "    },\n",
      "    \"model2pooling\": {\n",
      "      \"e5\": \"mean\",\n",
      "      \"bge\": \"cls\",\n",
      "      \"contriever\": \"mean\",\n",
      "      \"jina\": \"mean\",\n",
      "      \"dpr\": \"pooler\"\n",
      "    },\n",
      "    \"method2index\": {\n",
      "      \"e5\": null,\n",
      "      \"bm25\": null,\n",
      "      \"contriever\": null,\n",
      "      \"clip\": {\n",
      "        \"text\": \"path/to/text_index\",\n",
      "        \"image\": \"path/to/image_index\"\n",
      "      }\n",
      "    },\n",
      "    \"data_dir\": \"dataset/\",\n",
      "    \"save_dir\": \"output/\",\n",
      "    \"gpu_id\": \"0,1,2,3\",\n",
      "    \"dataset_name\": \"nq\",\n",
      "    \"split\": [\n",
      "      \"test\"\n",
      "    ],\n",
      "    \"test_sample_num\": null,\n",
      "    \"random_sample\": false,\n",
      "    \"seed\": 2024,\n",
      "    \"save_intermediate_data\": true,\n",
      "    \"save_note\": \"experiment\",\n",
      "    \"retrieval_method\": \"e5\",\n",
      "    \"retrieval_model_path\": null,\n",
      "    \"index_path\": null,\n",
      "    \"multimodal_index_path_dict\": null,\n",
      "    \"faiss_gpu\": false,\n",
      "    \"corpus_path\": null,\n",
      "    \"instruction\": null,\n",
      "    \"retrieval_topk\": 5,\n",
      "    \"retrieval_batch_size\": 256,\n",
      "    \"retrieval_use_fp16\": true,\n",
      "    \"retrieval_query_max_length\": 128,\n",
      "    \"save_retrieval_cache\": false,\n",
      "    \"use_retrieval_cache\": false,\n",
      "    \"retrieval_cache_path\": null,\n",
      "    \"retrieval_pooling_method\": null,\n",
      "    \"bm25_backend\": \"bm25s\",\n",
      "    \"use_sentence_transformer\": false,\n",
      "    \"silent_retrieval\": true,\n",
      "    \"seismic_query_cut\": 10,\n",
      "    \"seismic_heap_factor\": 0.8,\n",
      "    \"use_reranker\": false,\n",
      "    \"rerank_model_name\": null,\n",
      "    \"rerank_model_path\": null,\n",
      "    \"rerank_pooling_method\": null,\n",
      "    \"rerank_topk\": 5,\n",
      "    \"rerank_max_length\": 512,\n",
      "    \"rerank_batch_size\": 256,\n",
      "    \"rerank_use_fp16\": true,\n",
      "    \"use_multi_retriever\": false,\n",
      "    \"multi_retriever_setting\": {\n",
      "      \"merge_method\": \"concat\",\n",
      "      \"topk\": 5,\n",
      "      \"rerank_model_name\": null,\n",
      "      \"rerank_model_path\": null,\n",
      "      \"retriever_list\": [\n",
      "        {\n",
      "          \"retrieval_method\": \"e5\",\n",
      "          \"retrieval_topk\": 5,\n",
      "          \"index_path\": null,\n",
      "          \"retrieval_model_path\": \"/Volumes/KINGSTON/mid-point/models/e5-base-v2\",\n",
      "          \"instruction\": null,\n",
      "          \"bm25_backend\": \"bm25s\",\n",
      "          \"use_reranker\": false,\n",
      "          \"corpus_path\": null,\n",
      "          \"use_sentence_transformer\": false,\n",
      "          \"retrieval_pooling_method\": \"mean\",\n",
      "          \"retrieval_use_fp16\": true,\n",
      "          \"retrieval_query_max_length\": 128,\n",
      "          \"faiss_gpu\": false,\n",
      "          \"retrieval_batch_size\": 256,\n",
      "          \"rerank_model_name\": null,\n",
      "          \"rerank_model_path\": null,\n",
      "          \"retrieval_cache_path\": null,\n",
      "          \"save_retrieval_cache\": false,\n",
      "          \"use_retrieval_cache\": false\n",
      "        },\n",
      "        {\n",
      "          \"retrieval_method\": \"bm25\",\n",
      "          \"retrieval_topk\": 5,\n",
      "          \"index_path\": null,\n",
      "          \"retrieval_model_path\": \"bm25\",\n",
      "          \"instruction\": null,\n",
      "          \"bm25_backend\": \"bm25s\",\n",
      "          \"use_reranker\": false,\n",
      "          \"corpus_path\": null,\n",
      "          \"use_sentence_transformer\": false,\n",
      "          \"retrieval_pooling_method\": \"mean\",\n",
      "          \"retrieval_use_fp16\": true,\n",
      "          \"retrieval_query_max_length\": 128,\n",
      "          \"faiss_gpu\": false,\n",
      "          \"retrieval_batch_size\": 256,\n",
      "          \"rerank_model_name\": null,\n",
      "          \"rerank_model_path\": null,\n",
      "          \"retrieval_cache_path\": null,\n",
      "          \"save_retrieval_cache\": false,\n",
      "          \"use_retrieval_cache\": false\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"framework\": \"fschat\",\n",
      "    \"generator_model\": \"llama3-8B-instruct\",\n",
      "    \"openai_setting\": {\n",
      "      \"api_key\": null,\n",
      "      \"base_url\": null\n",
      "    },\n",
      "    \"generator_model_path\": null,\n",
      "    \"generator_max_input_len\": 1024,\n",
      "    \"generator_batch_size\": 4,\n",
      "    \"generation_params\": {\n",
      "      \"max_tokens\": 32\n",
      "    },\n",
      "    \"use_fid\": false,\n",
      "    \"gpu_memory_utilization\": 0.85,\n",
      "    \"metrics\": [\n",
      "      \"em\",\n",
      "      \"f1\",\n",
      "      \"acc\",\n",
      "      \"precision\",\n",
      "      \"recall\",\n",
      "      \"input_tokens\"\n",
      "    ],\n",
      "    \"metric_setting\": {\n",
      "      \"retrieval_recall_topk\": 5,\n",
      "      \"tokenizer_name\": \"gpt-4\"\n",
      "    },\n",
      "    \"save_metric_score\": true\n",
      "  },\n",
      "  \"final_config\": {\n",
      "    \"model2path\": {\n",
      "      \"e5\": \"/Volumes/KINGSTON/mid-point/models/e5-base-v2\",\n",
      "      \"bge\": \"BAAI/bge-base-en-v1.5\",\n",
      "      \"contriever\": \"facebook/contriever\",\n",
      "      \"llama2-7B-chat\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
      "      \"llama2-7B\": \"meta-llama/Llama-2-7b-hf\",\n",
      "      \"llama2-13B\": \"meta-llama/Llama-2-13b-hf\",\n",
      "      \"llama2-13B-chat\": \"meta-llama/Llama-2-13b-chat-hf\",\n",
      "      \"Qwen3Guard-Gen-0.6B\": \"/Volumes/KINGSTON/mid-point/models/Qwen3Guard-Gen-0.6B\"\n",
      "    },\n",
      "    \"model2pooling\": {\n",
      "      \"e5\": \"mean\",\n",
      "      \"bge\": \"cls\",\n",
      "      \"contriever\": \"mean\",\n",
      "      \"jina\": \"mean\",\n",
      "      \"dpr\": \"pooler\"\n",
      "    },\n",
      "    \"method2index\": {\n",
      "      \"e5\": null,\n",
      "      \"bm25\": null,\n",
      "      \"contriever\": null,\n",
      "      \"clip\": {\n",
      "        \"text\": \"path/to/text_index\",\n",
      "        \"image\": \"path/to/image_index\"\n",
      "      }\n",
      "    },\n",
      "    \"data_dir\": \"/Volumes/KINGSTON/mid-point/dataset\",\n",
      "    \"save_dir\": \"output/nq_2025_12_12_15_25_experiment\",\n",
      "    \"gpu_id\": \"0,1,2,3\",\n",
      "    \"dataset_name\": \"nq\",\n",
      "    \"split\": [\n",
      "      \"test\"\n",
      "    ],\n",
      "    \"test_sample_num\": null,\n",
      "    \"random_sample\": false,\n",
      "    \"seed\": 2024,\n",
      "    \"save_intermediate_data\": true,\n",
      "    \"save_note\": \"experiment\",\n",
      "    \"retrieval_method\": \"e5\",\n",
      "    \"retrieval_model_path\": \"/Volumes/KINGSTON/mid-point/models/e5-base-v2\",\n",
      "    \"index_path\": \"/Volumes/KINGSTON/mid-point/dataset/corpus/e5_Flat.index\",\n",
      "    \"multimodal_index_path_dict\": null,\n",
      "    \"faiss_gpu\": false,\n",
      "    \"corpus_path\": \"/Volumes/KINGSTON/mid-point/dataset/corpus/general_knowledge.jsonl\",\n",
      "    \"instruction\": null,\n",
      "    \"retrieval_topk\": 0,\n",
      "    \"retrieval_batch_size\": 256,\n",
      "    \"retrieval_use_fp16\": true,\n",
      "    \"retrieval_query_max_length\": 128,\n",
      "    \"save_retrieval_cache\": false,\n",
      "    \"use_retrieval_cache\": false,\n",
      "    \"retrieval_cache_path\": null,\n",
      "    \"retrieval_pooling_method\": \"mean\",\n",
      "    \"bm25_backend\": \"bm25s\",\n",
      "    \"use_sentence_transformer\": false,\n",
      "    \"silent_retrieval\": true,\n",
      "    \"seismic_query_cut\": 10,\n",
      "    \"seismic_heap_factor\": 0.8,\n",
      "    \"use_reranker\": false,\n",
      "    \"rerank_model_name\": null,\n",
      "    \"rerank_model_path\": null,\n",
      "    \"rerank_pooling_method\": null,\n",
      "    \"rerank_topk\": 5,\n",
      "    \"rerank_max_length\": 512,\n",
      "    \"rerank_batch_size\": 256,\n",
      "    \"rerank_use_fp16\": true,\n",
      "    \"use_multi_retriever\": false,\n",
      "    \"multi_retriever_setting\": {\n",
      "      \"merge_method\": \"concat\",\n",
      "      \"topk\": 5,\n",
      "      \"rerank_model_name\": null,\n",
      "      \"rerank_model_path\": null,\n",
      "      \"retriever_list\": [\n",
      "        {\n",
      "          \"retrieval_method\": \"e5\",\n",
      "          \"retrieval_topk\": 5,\n",
      "          \"index_path\": null,\n",
      "          \"retrieval_model_path\": \"/Volumes/KINGSTON/mid-point/models/e5-base-v2\",\n",
      "          \"instruction\": null,\n",
      "          \"bm25_backend\": \"bm25s\",\n",
      "          \"use_reranker\": false,\n",
      "          \"corpus_path\": null,\n",
      "          \"use_sentence_transformer\": false,\n",
      "          \"retrieval_pooling_method\": \"mean\",\n",
      "          \"retrieval_use_fp16\": true,\n",
      "          \"retrieval_query_max_length\": 128,\n",
      "          \"faiss_gpu\": false,\n",
      "          \"retrieval_batch_size\": 256,\n",
      "          \"rerank_model_name\": null,\n",
      "          \"rerank_model_path\": null,\n",
      "          \"retrieval_cache_path\": null,\n",
      "          \"save_retrieval_cache\": false,\n",
      "          \"use_retrieval_cache\": false\n",
      "        },\n",
      "        {\n",
      "          \"retrieval_method\": \"bm25\",\n",
      "          \"retrieval_topk\": 5,\n",
      "          \"index_path\": null,\n",
      "          \"retrieval_model_path\": \"bm25\",\n",
      "          \"instruction\": null,\n",
      "          \"bm25_backend\": \"bm25s\",\n",
      "          \"use_reranker\": false,\n",
      "          \"corpus_path\": null,\n",
      "          \"use_sentence_transformer\": false,\n",
      "          \"retrieval_pooling_method\": \"mean\",\n",
      "          \"retrieval_use_fp16\": true,\n",
      "          \"retrieval_query_max_length\": 128,\n",
      "          \"faiss_gpu\": false,\n",
      "          \"retrieval_batch_size\": 256,\n",
      "          \"rerank_model_name\": null,\n",
      "          \"rerank_model_path\": null,\n",
      "          \"retrieval_cache_path\": null,\n",
      "          \"save_retrieval_cache\": false,\n",
      "          \"use_retrieval_cache\": false\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"framework\": \"fschat\",\n",
      "    \"generator_model\": \"Qwen3Guard-Gen-0.6B\",\n",
      "    \"openai_setting\": {\n",
      "      \"api_key\": null,\n",
      "      \"base_url\": null\n",
      "    },\n",
      "    \"generator_model_path\": \"/Volumes/KINGSTON/mid-point/models/Qwen3Guard-Gen-0.6B\",\n",
      "    \"generator_max_input_len\": 1024,\n",
      "    \"generator_batch_size\": 4,\n",
      "    \"generation_params\": {\n",
      "      \"max_tokens\": 32\n",
      "    },\n",
      "    \"use_fid\": false,\n",
      "    \"gpu_memory_utilization\": 0.85,\n",
      "    \"metrics\": [\n",
      "      \"em\",\n",
      "      \"f1\",\n",
      "      \"acc\"\n",
      "    ],\n",
      "    \"metric_setting\": {\n",
      "      \"retrieval_recall_topk\": 5,\n",
      "      \"tokenizer_name\": \"gpt-4\"\n",
      "    },\n",
      "    \"save_metric_score\": true,\n",
      "    \"dataset_dir\": \"/Volumes/KINGSTON/mid-point/dataset\",\n",
      "    \"dataset_path\": \"/Volumes/KINGSTON/mid-point/dataset/nq\",\n",
      "    \"gpu_num\": 0,\n",
      "    \"device\": \"cpu\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(config if isinstance(config, dict) else getattr(config, \"__dict__\", config),\n",
    "                 indent=2, ensure_ascii=False, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c8b6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/KINGSTON/mid-point/dataset/nq/test.jsonl\n",
      "Loading test dataset from: /Volumes/KINGSTON/mid-point/dataset/nq/test.jsonl...\n"
     ]
    }
   ],
   "source": [
    "all_split = get_dataset(config)\n",
    "test_data = all_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1fd50cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/KINGSTON/mid-point/dataset/nq/test.jsonl\n",
      "Loading test dataset from: /Volumes/KINGSTON/mid-point/dataset/nq/test.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Generation process: 100%|██████████| 903/903 [53:31<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'em': 0.0, 'f1': 0.053184656004268915, 'acc': 0.11772853185595568}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_split = get_dataset(config)\n",
    "test_data = all_split[\"test\"]\n",
    "\n",
    "\n",
    "\n",
    "templete = PromptTemplate(\n",
    "    config=config,\n",
    "    system_prompt=\"Answer the question based on your own knowledge. Only give me the answer and do not output any other words.\",\n",
    "    user_prompt=\"Question: {question}\",\n",
    ")\n",
    "pred_process_fun = lambda x: x.split(\"\\n\")[0]\n",
    "pipeline = SequentialPipeline(config, templete)\n",
    "result = pipeline.naive_run(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756d1cb",
   "metadata": {},
   "source": [
    "# CrowS-pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa48d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = { \n",
    "    'data_dir': f'{parent}/dataset',\n",
    "    'dataset_dir': f'{parent}/dataset',\n",
    "    'dataset_path': f'{parent}/dataset',\n",
    "    \"dataset_name\": \"crows-pairs\",\n",
    "    'split': 'crows_formatted',\n",
    "    'index_path': f'{parent}/dataset/corpus/e5_Flat.index',\n",
    "    'corpus_path': f'{parent}/dataset/corpus/general_knowledge.jsonl',\n",
    "    'model2path': {'e5': f'{parent}/models/e5-base-v2', 'Qwen3Guard-Gen-0.6B': f'{parent}/models/Qwen3Guard-Gen-0.6B'},\n",
    "    'generator_model': 'Qwen3Guard-Gen-0.6B',\n",
    "    'metrics': ['em', 'f1', 'acc'],\n",
    "    'retrieval_topk': 0\n",
    "}\n",
    "\n",
    "config = Config(config_dict=config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e1b671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/KINGSTON/mid-point/dataset/crows-pairs/crows_formatted.jsonl\n",
      "Loading crows_formatted dataset from: /Volumes/KINGSTON/mid-point/dataset/crows-pairs/crows_formatted.jsonl...\n"
     ]
    }
   ],
   "source": [
    "all_split = get_dataset(config)\n",
    "test_data = all_split[\"crows_formatted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b90a382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation process: 100%|██████████| 377/377 [29:19<00:00,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'em': 0.42838196286472147, 'f1': 0.009040590650230874, 'acc': 0.9018567639257294}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "templete = PromptTemplate(\n",
    "    config=config,\n",
    "    system_prompt=\"Answer the question based on your own knowledge. Only give me the answer and do not output any other words.\",\n",
    "    user_prompt=\"Question: {question}\",\n",
    ")\n",
    "pred_process_fun = lambda x: x.split(\"\\n\")[0]\n",
    "pipeline = SequentialPipeline(config, templete)\n",
    "result = pipeline.naive_run(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flashragtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
